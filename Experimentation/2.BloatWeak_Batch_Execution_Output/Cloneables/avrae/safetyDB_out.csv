,dep,version,filepath,bloated,cve,affected versions,advisory
0,launchdarkly-server-sdk,==7.2.0,/home/daniele/git/NICHE_projects/Repo/Cloneables/avrae/requirements.txt,False,no one,no one,no one
1,aiobotocore,==2.1.0,/home/daniele/git/NICHE_projects/Repo/Cloneables/avrae/requirements.txt,False,no one,no one,no one
2,python-meteor,==0.1.6,/home/daniele/git/NICHE_projects/Repo/Cloneables/avrae/requirements.txt,False,no one,no one,no one
3,d20,==1.1.2,/home/daniele/git/NICHE_projects/Repo/Cloneables/avrae/requirements.txt,False,no one,no one,no one
4,aiohttp,~=3.8.0,/home/daniele/git/NICHE_projects/Repo/Cloneables/avrae/requirements.txt,False,no one,no one,no one
5,dnspython,==2.1.0,/home/daniele/git/NICHE_projects/Repo/Cloneables/avrae/requirements.txt,False,no one,no one,no one
6,google-auth,==2.13.0,/home/daniele/git/NICHE_projects/Repo/Cloneables/avrae/requirements.txt,False,no one,no one,no one
7,pymongo,==3.11.3,/home/daniele/git/NICHE_projects/Repo/Cloneables/avrae/requirements.txt,False,no one,no one,no one
8,Pillow,==9.0.1,/home/daniele/git/NICHE_projects/Repo/Cloneables/avrae/requirements.txt,False,CVE-2014-3589,"<2.3.2,>=2.5.0,<2.5.2","Pillow versions 2.3.2 and 2.5.2 include a fix for CVE-2014-3589: PIL/IcnsImagePlugin.py in Python Imaging Library (PIL) and Pillow before 2.3.2 and 2.5.x before 2.5.2 allows remote attackers to cause a denial of service via a crafted block size.
https://github.com/python-pillow/Pillow/commit/205e056f8f9b06ed7b925cf8aa0874bc4aaf8a7d"
9,Pillow,==9.0.1,/home/daniele/git/NICHE_projects/Repo/Cloneables/avrae/requirements.txt,False,CVE-2022-45198,<9.2.0,Pillow before 9.2.0 performs Improper Handling of Highly Compressed GIF Data (Data Amplification).
10,Pillow,==9.0.1,/home/daniele/git/NICHE_projects/Repo/Cloneables/avrae/requirements.txt,False,CVE-2021-28675,">=0,<8.2.0",An issue was discovered in Pillow before 8.2.0. PSDImagePlugin.PsdImageFile lacked a sanity check on the number of input layers relative to the size of the data block. This could lead to a DoS on Image.open prior to Image.load.
11,Pillow,==9.0.1,/home/daniele/git/NICHE_projects/Repo/Cloneables/avrae/requirements.txt,False,CVE-2021-27923,">=4.3.0,<8.1.1","Pillow before 8.1.1 allows attackers to cause a denial of service (memory consumption) because the reported size of a contained image is not properly checked for an ICO container, and thus an attempted memory allocation can be very large."
12,Pillow,==9.0.1,/home/daniele/git/NICHE_projects/Repo/Cloneables/avrae/requirements.txt,False,CVE-2021-23437,">=5.2.0,<8.3.2","Pillow from 5.2.0 and before 8.3.2 is vulnerable to Regular Expression Denial of Service (ReDoS) via the getrgb function.
https://github.com/python-pillow/Pillow/commit/9e08eb8f78fdfd2f476e1b20b7cf38683754866b
https://pillow.readthedocs.io/en/stable/releasenotes/8.3.2.html"
13,Pillow,==9.0.1,/home/daniele/git/NICHE_projects/Repo/Cloneables/avrae/requirements.txt,False,CVE-2022-30595,">=9.1.0,<9.1.1",libImaging/TgaRleDecode.c in Pillow 9.1.0 has a heap buffer overflow in the processing of invalid TGA image files.
14,Pillow,==9.0.1,/home/daniele/git/NICHE_projects/Repo/Cloneables/avrae/requirements.txt,False,PVE-2023-55182,">=9.1.0,<9.3.0","Pillow 9.3.0 includes a security fix: Pillow will now decode the data in its natural CMYK mode, then convert it to RGB and rearrange the channels afterwards. Trying to load the data in an incorrect mode could result in a segmentation fault.
https://pillow.readthedocs.io/en/stable/releasenotes/9.3.0.html#decode-jpeg-compressed-blp1-data-in-original-mode"
15,Pillow,==9.0.1,/home/daniele/git/NICHE_projects/Repo/Cloneables/avrae/requirements.txt,False,CVE-2022-45199,">=9.2.0,<9.3.0","Pillow before 9.3.0 allows denial of service via SAMPLESPERPIXEL.
https://pillow.readthedocs.io/en/stable/releasenotes/9.3.0.html#limit-samplesperpixel-to-avoid-runtime-dos"
16,pydantic,~=1.9.0,/home/daniele/git/NICHE_projects/Repo/Cloneables/avrae/requirements.txt,False,CVE-2020-10735,<1.10.2,"Pydantic 1.10.2 prevents long strings as int inputs to fix CVE-2020-10735.
https://github.com/pydantic/pydantic/commit/eccd85e4d012e70ffbd81f379179da900d4621c5"
17,pydantic,~=1.9.0,/home/daniele/git/NICHE_projects/Repo/Cloneables/avrae/requirements.txt,False,CVE-2021-29510,">=1.8.0a1,<1.8.2,>=1.7.0a0,<1.7.4,<1.6.2","Pydantic 1.8.2, 1.7.4 and 1.6.2 include a fix for CVE-2021-29510: In affected versions of Pydantic passing either `'infinity'`, `'inf'` or `float('inf')` (or their negatives) to `datetime` or `date` fields causes validation to run forever with 100% CPU usage (on one CPU). Pydantic has been patched with fixes available in the following versions: v1.8.2, v1.7.4, v1.6.2. All these versions are available on pypi(https://pypi.org/project/pydantic/#history), and will be available on conda-forge(https://anaconda.org/conda-forge/pydantic) soon. See the changelog(https://pydantic-docs.helpmanual.io/) for details. If you absolutely can't upgrade, you can work around this risk using a validator(https://pydantic-docs.helpmanual.io/usage/validators/) to catch these values. This is not an ideal solution (in particular you'll need a slightly different function for datetimes), instead of a hack like this you should upgrade pydantic. If you are not using v1.8.x, v1.7.x or v1.6.x and are unable to upgrade to a fixed version of pydantic, please create an issue at https://github.com/samuelcolvin/pydantic/issues requesting a back-port, and we will endeavour to release a patch for earlier versions of pydantic."
18,boto3,==1.20.24,/home/daniele/git/NICHE_projects/Repo/Cloneables/avrae/requirements.txt,False,no one,no one,no one
19,httplib2,==0.19.0,/home/daniele/git/NICHE_projects/Repo/Cloneables/avrae/requirements.txt,False,CVE-2013-2037,">=0,<0.9","httplib2 0.7.2, 0.8, and earlier, after an initial connection is made, does not verify that the server hostname matches a domain name in the subject's Common Name (CN) or subjectAltName field of the X.509 certificate, which allows man-in-the-middle attackers to spoof SSL servers via an arbitrary valid certificate."
20,redis,==4.6.0,/home/daniele/git/NICHE_projects/Repo/Cloneables/avrae/requirements.txt,False,CVE-2023-28858,"<4.3.6,>=4.4.0rc1,<4.4.3,>=4.5.0rc1,<4.5.3","Redis before 4.5.3 leaves a connection open after canceling an async Redis command at an inopportune time, and can send response data to the client of an unrelated request in an off-by-one manner. NOTE: this CVE Record was initially created in response to reports about ChatGPT, and 4.3.6, 4.4.3, and 4.5.3 were released (changing the behavior for pipeline operations); however, please see CVE-2023-28859 about addressing data leakage across AsyncIO connections in general."
21,redis,==4.6.0,/home/daniele/git/NICHE_projects/Repo/Cloneables/avrae/requirements.txt,False,CVE-2023-28859,"<4.4.4,>=4.5.0rc0,<4.5.4","Redis 4.4.4 and 4.5.4 include a fix for CVE-2023-28859: Redis-py before 4.4.4 and 4.5.x before 4.5.4 leaves a connection open after canceling an async Redis command at an inopportune time, and can send response data to the client of an unrelated request. (This could, for example, happen for a non-pipeline operation.) NOTE: the solutions for CVE-2023-28859 address data leakage across AsyncIO connections in general."
22,pyjwt,==2.4.0,/home/daniele/git/NICHE_projects/Repo/Cloneables/avrae/requirements.txt,False,CVE-2022-29217,">=1.5.0,<2.4.0","PyJWT 2.4.0 includes a fix for CVE-2022-29217: An attacker submitting the JWT token can choose the used signing algorithm. The PyJWT library requires that the application chooses what algorithms are supported. The application can specify 'jwt.algorithms.get_default_algorithms()' to get support for all algorithms, or specify a single algorithm. The issue is not that big as 'algorithms=jwt.algorithms.get_default_algorithms()' has to be used. As a workaround, always be explicit with the algorithms that are accepted and expected when decoding."
23,psutil,==5.8.0,/home/daniele/git/NICHE_projects/Repo/Cloneables/avrae/requirements.txt,False,no one,no one,no one
24,cachetools,==4.2.2,/home/daniele/git/NICHE_projects/Repo/Cloneables/avrae/requirements.txt,False,no one,no one,no one
25,markdownify,==0.9.4,/home/daniele/git/NICHE_projects/Repo/Cloneables/avrae/requirements.txt,False,no one,no one,no one
26,botocore,==1.23.24,/home/daniele/git/NICHE_projects/Repo/Cloneables/avrae/requirements.txt,False,no one,no one,no one
27,gspread,==3.7.0,/home/daniele/git/NICHE_projects/Repo/Cloneables/avrae/requirements.txt,False,no one,no one,no one
28,ddtrace,>=0.59.1,/home/daniele/git/NICHE_projects/Repo/Cloneables/avrae/requirements.txt,False,no one,no one,no one
29,sentry-sdk,==1.3.0,/home/daniele/git/NICHE_projects/Repo/Cloneables/avrae/requirements.txt,False,CVE-2023-28117,<1.14.0,"Sentry-sdk 1.14.0 includes a fix for CVE-2023-28117: When using the Django integration of versions prior to 1.14.0 of the Sentry SDK in a specific configuration it is possible to leak sensitive cookies values, including the session cookie to Sentry. These sensitive cookies could then be used by someone with access to your Sentry issues to impersonate or escalate their privileges within your application. In order for these sensitive values to be leaked, the Sentry SDK configuration must have 'sendDefaultPII' set to 'True'; one must use a custom name for either 'SESSION_COOKIE_NAME' or 'CSRF_COOKIE_NAME' in one's Django settings; and one must not be configured in one's organization or project settings to use Sentry's data scrubbing features to account for the custom cookie names. As of version 1.14.0, the Django integration of the 'sentry-sdk' will detect the custom cookie names based on one's Django settings and will remove the values from the payload before sending the data to Sentry. As a workaround, use the SDK's filtering mechanism to remove the cookies from the payload that is sent to Sentry. For error events, this can be done with the 'before_send' callback method and for performance related events (transactions) one can use the 'before_send_transaction' callback method. Those who want to handle filtering of these values on the server-side can also use Sentry's advanced data scrubbing feature to account for the custom cookie names. Look for the '$http.cookies', '$http.headers', '$request.cookies', or '$request.headers' fields to target with a scrubbing rule.
https://github.com/getsentry/sentry-python/security/advisories/GHSA-29pr-6jr8-q5jm"
30,motor,==2.3.1,/home/daniele/git/NICHE_projects/Repo/Cloneables/avrae/requirements.txt,False,no one,no one,no one
31,pyyaml,==6.0.1,/home/daniele/git/NICHE_projects/Repo/Cloneables/avrae/requirements.txt,False,CVE-2019-20477,">=5.1,<=5.1.2","PyYAML 5.1 through 5.1.2 has insufficient restrictions on the load and load_all functions because of a class deserialization issue, e.g., Popen is a class in the subprocess module. See CVE-2019-20477. NOTE: this issue exists because of an incomplete fix for CVE-2017-18342."
32,rapidfuzz,==2.0.11,/home/daniele/git/NICHE_projects/Repo/Cloneables/avrae/requirements.txt,False,no one,no one,no one
33,disnake,~=2.7.0,/home/daniele/git/NICHE_projects/Repo/Cloneables/avrae/requirements.txt,False,no one,no one,no one
34,pytest-asyncio,==0.18.3,/home/daniele/git/NICHE_projects/Repo/Cloneables/avrae/tests/requirements.txt,False,no one,no one,no one
35,pytest,==7.0.1,/home/daniele/git/NICHE_projects/Repo/Cloneables/avrae/tests/requirements.txt,False,no one,no one,no one
36,pre-commit,==2.17.0,/home/daniele/git/NICHE_projects/Repo/Cloneables/avrae/tests/requirements.txt,False,no one,no one,no one
37,pytest-cov,==3.0.0,/home/daniele/git/NICHE_projects/Repo/Cloneables/avrae/tests/requirements.txt,False,no one,no one,no one
38,black,==23.3.0,/home/daniele/git/NICHE_projects/Repo/Cloneables/avrae/tests/requirements.txt,False,no one,no one,no one
39,sphinx-rtd-theme,==1.0.0,/home/daniele/git/NICHE_projects/Repo/Cloneables/avrae/docs/requirements.txt,False,no one,no one,no one
40,Sphinx,==4.2.0,/home/daniele/git/NICHE_projects/Repo/Cloneables/avrae/docs/requirements.txt,False,no one,no one,no one
